?dbConnect
?DBIDriver
?MySQL
?dbGetQuery
source('C:/Users/Dave/Desktop/Data Science/RWD/Genome.Connect.R')
genome.connect()
result
source('C:/Users/Dave/Desktop/Data Science/RWD/Genome.Connect.R')
genome.connect()
?save
source('C:/Users/Dave/Desktop/Data Science/RWD/Genome.Connect.R')
genome.connect()
source('C:/Users/Dave/Desktop/Data Science/RWD/Genome.Connect.R')
genome.connect()
source('C:/Users/Dave/Desktop/Data Science/RWD/Genome.Connect.R')
genome.connect()
source("dumpdata.R")
ucscDb <- dbConnect(MySQL(), user="genome", host = "genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb, "show databases;")
dbDisconnect(ucscDb);
result
head(result)
head(result, 10)
hg19 <- dbConnect(MySQL(), user="genome", db = "hg19", host = "genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
head(allTables)
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from AffyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fetch(query); quantile(affyMis$misMatches)
affyMisSmall <- fetch(query, n=10); dbClearResult(query);
dim(affyMisSmall)
dbDisconnect(hg19)
?myapp
??myapp
??oatch
??oauth
?oath2.0token
??oath2.0token
??oauth2.0token
?oauth2.0token
?oauth2.0_token
??oauth2.0_token
library("httr", lib.loc="~/R/win-library/3.1")
?config
?token
??token
?GET
myapp <- oauth_app("github", key = "55d5c3fc8c1ba5714f81", secret = "e03bece6945a3a09f8400220522cb1b4ced48ff6")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
install.packages("httpuv")
library("httpuv")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
source('C:/Users/Dave/Desktop/Data Science/RWD/Genome.Connect.R')
quit()
?download.file
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile = "Q2.csv")
list.files()
acs <- read.csv("Q2.csv")
install.packages(sqldf)
install.packages("sqldf")
library(sqldf)
dim(acs)
colnames(acs)
acs$pwgtp1[10]
acs$pwgtp1[1:10]
pwgtp1 <- acs$pwgtp1
str(pwgtp1)
pwgtp1[pwgtp1 < 50]
length(pwgtp1[pwgtp1 < 50])
pwg.lessThan50 <- pwgtp1[pwgtp1 < 50]
pwg.lessThan50
max(pwg.lessThan50)
rm(pwg.lessThan50)
rm(pwgtp1)
pwgtp1 <- acs[AGEP > 50, pwgtp1]
pwgtp1 <- acs[AGEP > 50, acs$pwgtp1]
pwgtp1 <- acs[acs$AGEP > 50, acs$pwgtp1]
pwgtp1 <- acs[acs$AGEP < 50,acs$pwgtp1]
acs[acs$AGEP < 50,acs$pwgtp1]
pwgtp1 <- subset(acs, subset = acs[AGEP,] < 50, select = "pwgtp1")
class(acs$AGEP)
pwgtp1 <- subset(acs, subset = acs$AGEP < 50, select = "pwgtp1")
head(pwgtp1,15)
pwgtp1 <- subset(acs, subset = acs$AGEP < 50, select = c("AGEP", "pwgtp1")
)
head(pwgtp1)
max(pwgtp1[,1])
str(pwgtp1)
pwgtp1.2 <- sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select * from acs where AGEP < 50 and pwgtp1")
acs <- read.csv.sql("Q2.csv")
rm(acs)
acs <- read.csv.sql("Q2.csv")
sqldf("select * from acs where AGEP < 50 and pwgtp1")
sqldf("select pwgtp1 from acs")
?sqldf
class(acs)
sqldf("select pwgtp1 form acs")
sqldf("create table 'acs")
sqldf("create table 'acs'")
sqldf("select pwgtp1 form acs", drv='SQLite')
sqldf("select * from acs where AGEP < 50 and pwgtp1", drv = 'SQLite')
temp <- sqldf("select pwgtp1 from acs where AGEP < 50", drv = 'SQLite')
length(temp)
temp
dim(temp)
unique.age <- unique(acs$AGEP)
unique.age
length(unique.age)
temp2 <- sqldf("select distinct AGEP from acs", drv="SQLite")
length(temp2)
dim(temp2)
as.vector(temp2)
length(as.vector(temp2))
download.file(url = "http://biostat.jhsph.edu/~jleek/contact.html", destfile = "Q4.html")
?parseHTMLTree
library(XML)
install.packages("XML")
library("XML", lib.loc="~/R/win-library/3.1")
htmlfile <- htmlTreeParse("Q4.html")
htmlfile
dim(htmlfile)
class(htmlfile)
htmlfile[1]
htmlfile[2]
htmlfile[3]
htmlfile[3][[1]]
htmlfile[3][[1]][[1]]
htmlfile <- htmlTreeParse("Q4.html", asText = TRUE)
htmlfile
htmlfile <- htmlParse("Q4.html", asText = TRUE)
htmlfile
htmlfile <- htmlParse("Q4.html")
htmlfile
class(htmlfile)
dim(htmlfile)
htmlfile[1]
htmlfile[row = 1]
?htmlParse
??html
?readLines
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
htmlfile <- readLines(url)
htmlfile
lines <- c(10,20,30,100)
htmlfile[lines]
dim(htmlfile)
htmlfile[10]
htmlfile[20]
htmlfile[30]
nchar(htmlfile[lines])
close(con)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",destfile = "Q5.for")
??fixed width
??fixedwidth
df <- read.fwf("Q5.for")
df <- read.fwf("Q5.for", widths = 14)
head(df)
df <- read.fwf("Q5.for", widths = 14, skip = 3, header = TRUE)
head(df)
source('C:/Users/Dave/Desktop/Data Science/RWD/Genome.Connect.R')
ruler()
?readLines
ruler
ruler()
source('C:/Users/Dave/Desktop/Data Science/RWD/Genome.Connect.R')
ruler()
source('C:/Users/Dave/Desktop/Data Science/RWD/Genome.Connect.R')
ruler()
source('C:/Users/Dave/Desktop/Data Science/RWD/Genome.Connect.R')
ruler()
linewd <- c(9, 5, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4)
?read.fwf
df <- read.fwf("Q5.for", widths = linewd, header = TRUE, skip = 3)
df <- read.fwf("Q5.for", widths = linewd, skip = 4)
head(df)
df[1]
df[,1]
class(df)
df[1,1]
class(df[,1])
df[,1] <- as.character(df[,1])
class(df[,1])
df[1,1]
linewd
linewd <- c(1, 9, 5, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4)
df <- read.fwf("Q5.for", widths = linewd, skip = 4)
df[1]
head(df)
c(2, 4, 5, 7, 8, 10, 11, 13, 14)
keep <- c(2, 4, 5, 7, 8, 10, 11, 13, 14)
df2 <- df[,keep]
head(df2)
df[1,1]
df2[1,1]
df2[,1] <- as.character(df2[,1])
head(df2)
rm(df)
df2[1,1]
sum(df2[,4])
myapp <- oauth_app("github", key = "55d5c3fc8c1ba5714f81", secret = "e03bece6945a3a09f8400220522cb1b4ced48ff6")
library("httr")
myapp <- oauth_app("github", key = "55d5c3fc8c1ba5714f81", secret = "e03bece6945a3a09f8400220522cb1b4ced48ff6")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
req
class(req)
??JSON
req[2]
req[3]
req[4]
req[5]
req[6]
req[7]
req[8]
req[9]
req[3][[1]]
library("jsonlite", lib.loc="~/R/win-library/3.1")
fromJSON(req)
class(req)
??response
temp <- content(req, as = "parsed")
str(temp)
temp[1]
temp[2]
temp[1][[1]]
temp[1][[1]][1]
temp[1][[1]][2]
x <- 1:30
temp[x][[1]][2]
temp[2][[1]][2]
temp[3][[1]][2]
temp[4][[1]][2]
temp[5][[1]][2]
temp[6][[1]][2]
temp$name == "datasharing"
temp[temp$name == "datasharing"]
temp[temp$name == "datasharing",]
temp[,temp$name == "datasharing"]
temp[temp$name == "datasharing"]
y <- temp[temp$name == "datasharing"]
y
rm(y)
temp[5]
y <- 1:50
for(i in 1:50){name <- temp[5][[1]][i]}
y
temp[5][[1]][1]
temp[5][[1]][2]
name
for(i in 1:50){name[i] <- temp[5][[1]][i]}
name
temp[5][[1]][1]
temp[5][[1]][2]
temp[5][[1]][3]
temp[5][[1]][45:47]
temp1 <- content(req, as = "text")
class(temp1)
temp1
temp1 <- content(req, as = "raw")
temp1[1]
temp1[2]
class(temp)
temp[1]
temp[1][1]
temp[1][1][1]
rm(temp1)
?list
temp[1][[1][[1]]]
temp[1][[1][[1]]
temp[1][[1]][[1]]
temp[1][[1]]
class(temp[1])
class(temp[1][[1]])
class(temp[1][[1]][[1]])
temp1 <- unlist(temp)
temp1
class(temp1)
temp1[1]
length(temp1)
temp[1][[1]][1]
temp[1][[2]][1]
temp[1][[3]][1]
temp[1][[1]][2]
temp[1][[1]][3]
temp[2][[1]][2]
temp[1:30][[1]][2]
for(i in 1:30){temp1 <- temp[i][[1]][2]}
temp1
for(i in 1:30){temp1[i] <- temp[i][[1]][2]}
temp1
temp[5]
names(temp[1])
dimnames(temp[1][[1]])
dimnames(temp[1][[2]])
dimnames(temp[1][[1]])
?list
name <- "created_at"
temp[[name]]
temp[5][[name]]
temp[5][[name]][1]
temp[5][["created_at"]]
temp[5][[45]]
temp[5][[45]][1]
temp[5][[1]][45]
temp[5][[1]][name]
temp[5]["created_at"]
temp[5]["created_at"]
?read.fwf
getwd()
list.files()
data <- read.csv("Charm_City_Circulator_Ridership.csv")
str(dat)
str(data)
data2 <- data[,c(1, 2, 5, 8, 11, 14, 15)]
str(data2)
head(data2,4)
head(data2,4)
class(date)
c("01/16/2010", "06/17/2010", "03/7/2012", "07/4/2012", "10/29/2012")
day <- c("01/16/2010", "06/17/2010", "03/7/2012", "07/4/2012", "10/29/2012")
data[data$date %in% day,]
data[data$date %in% day[1],]
day
data[data$date %in% day]
data[data$date %in% day,]
data[data$date == day,]
data[data$date %in% c("1/11/2010", "1/12/2010"),]
data[data$date %in% c("01/16/2010", "06/17/2010", "03/7/2012", "07/4/2012", "10/29/2012"),]
data[data$date %in% c("1/16/2010", "6/17/2010", "3/7/2012", "7/4/2012", "10/29/2012"),]
data2[data2$date %in% c("1/16/2010", "6/17/2010", "3/7/2012", "7/4/2012", "10/29/2012"),]
data[is.na(data$daily),]
head(data2)
?which
zero.riders <- which(data2$orangeAverage == 0 & data2$purpleAverage == 0)
zero.riders
zero.riders <- which(data2$orangeAverage == 0 & data2$purpleAverage == 0 & data2$greenAverage == 0 & data2$bannerAverage == 0)
zero.riders
View(data)
View(data)
View(data2)
zero.riders <- which(data2$daily == 0)
zero.riders
data2$date[zero.riders,]
data2$date[zero.riders]
?average
?mean
mean(data2$daily)
mean(data2$daily, na.rm = TRUE)
mean(data2$daily[data2$day == "Monday",], na.rm = TRUE)
mean(data2$daily[data2$day == "Monday"], na.rm = TRUE)
mean(data2$daily[data2$day == "Tuesday"], na.rm = TRUE)
mean(data2$daily[data2$day == "Wednesday"], na.rm = TRUE)
?days
?Days
Days()
Day()
daysOfWeek()
Days <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
?sapply
sapply(data2[data2$day == Days,], mean)
sapply(data2[data2$day == Days,], mean, na.rm = TRUE)
sapply(data2$daily[data2$day == Days,], mean, na.rm = TRUE)
mean(data2$daily[data2$day == "Thursday"], na.rm = TRUE)
mean(data2$daily[data2$day == "Friday"], na.rm = TRUE)
mean(data2$daily[data2$day == "Saturday"], na.rm = TRUE)
quit()
setwd("C:/Users/Dave/Desktop/Data Science/Getting and Cleaning Data/getdata-projectfiles-UCI HAR Dataset/UCI HAR Dataset")
setwd("~/GitHub/Get-and-Clean-Project/Data")
list.files()
rm(data)
rm(data2)
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
merge_data()
head(test.data.g)
head(train.data.g)
str(test.data.g)
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
merge_data()
str(test.data.g)
head(test.data.g)
View(test.data.g)
x <- c(1, 2, 3, 4, 5, 6)
y <- c(6, 5, 4, 3, 2, 1)
rbind(x,y)
rbind(y,x)
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
list.files()
features <- read.table("features.txt")
head(features)
feature <- c("subject.number", "activity.name", as.character(features[,2]))
head(feature)
colnames(test.data.g) <- features
head(test.data.g)
colnames(test.data.g) <- feature
head(colnames)
head(test.data.g)
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
merge_data()
merge_data()
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
merge_data()
?colnames
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
merge_data()
test.names <- names(test.data.g)
train.names <- names(train.data.g)
?identical
identical(test.names, train.names)
head(names(test.data.g))
head(names(train.data.g))
test.data.g <- unname(test.data.g)
names(test.data.g)
train.data.g <- unname(names(train.data.g[,2])
)
head(names(train.data.g))
rm(list = ls())
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
merge_data()
?rbind
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
merge_data()
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
merge_data()
head(all.data.g)
dim(all.data.g)
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
?write
?write.table
?write.csv
write.csv(all.data.g, "alldata.csv")
feature.data <- read.table("features.txt")
?grep
x <- c("Dave", "Eric", "Fred", "Carl", "Horace", "Jim")
grep(x, "e")
grep("e", x)
grep(("e"|"E"), x)
grep("e", x)
grep("e", x, value = TRUE)
grep("std", feature.data)
head(feature.data)
grep("std", feature.data[,2])
grep("mean", feature.data[,2])
grep("mean", feature.data[,2], value = TRUE)
grep("Mean", feature.data[,2], value = TRUE)
grep("Std", feature.data[,2], value = TRUE)
grep("std", feature.data[,2], value = TRUE)
mean.vector <- grep("mean", feature.data[,2], value = TRUE)
std.vector <- grep("std", feature.data[,2], value = TRUE)
mean.vector <- grep("mean", feature.data[,2], value)
mean.vector <- grep("mean", feature.data[,2])
std.vector <- grep("std", feature.data[,2])
all.vector <- paste(mean.vector, std.vector)
all.vector <- sort(all.vector)
all.vector
rm(all.vector)
c(mean.vector, std.vector)
all.vector <- c(mean.vector, std.vector)
all.vector <- sort(all.vector)
all.vector
all.features <- feature.data[all.vector,2]
head(all.features)
length(all.features)
all.features
drop.levels(all.features)
?droplevels
all.features <- droplevels(all.features)
all.features
all.features <- as.character(all.features)
all.features
grep(c("e", "E"), x)
?grep
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
merge_data()
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
merge_data()
dim(extracted.data.g)
names(extracted.data.g)
head(extracted.data.g)
?sort
sorted.data <- order(extracted.data.g[,1], extracted.data.g[,2])
head(sorted.data)
sorted.index <- order(extracted.data.g[,1], extracted.data.g[,2])
sorted.data <- extracted.data.g[sorted.index,]
head(sorted.data)
View(sorted.data)
?ftable
rm(list=ls())
gender = rep(c("female","male"),c(1835,2691))
admitted = rep(c("yes","no","yes","no"),c(557,1278,1198,1493))
dept = rep(c("A","B","C","D","E","F","A","B","C","D","E","F"),
c(89,17,202,131,94,24,19,8,391,244,299,317))
dept2 = rep(c("A","B","C","D","E","F","A","B","C","D","E","F"),
c(512,353,120,138,53,22,313,207,205,279,138,351))
department = c(dept,dept2)
ucb = data.frame(gender,admitted,department)
rm(gender,admitted,dept,dept2,department)
ls()
head(ucb)
str(ucb)
summary(ucb)
source('~/GitHub/Get-and-Clean-Project/Merge_Data.R')
